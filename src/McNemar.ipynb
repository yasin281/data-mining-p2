{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b16a4993",
   "metadata": {},
   "source": [
    "## McNerman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38266d6-c1f6-4f30-b8e2-a4ab0ea23903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (2.2.5)\n",
      "Requirement already satisfied: seaborn in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: pandas in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (3.10.3)\n",
      "Requirement already satisfied: scikit-learn in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: statsmodels in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (0.14.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/javier/Desktop/Uni/MD/data-mining-p2/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Dataset loaded successfully.\n",
      "   Modelo A Modelo B  b (A acierta, B falla)  c (A falla, B acierta)      χ²  \\\n",
      "0        NB       DT                     297                     303   0.042   \n",
      "1        NB      ADA                     209                     299  15.593   \n",
      "2        NB      KNN                     225                     227   0.002   \n",
      "3        NB      BAG                     255                     281   1.166   \n",
      "4        NB     PIPE                     172                     257  16.448   \n",
      "5        NB      SVM                     135                     231  24.658   \n",
      "6        NB       RF                     225                     273   4.436   \n",
      "7        NB       MV                     194                     250   6.813   \n",
      "8        DT      ADA                     120                     204  21.262   \n",
      "9        DT      KNN                     284                     280   0.016   \n",
      "10       DT      BAG                     227                     247   0.762   \n",
      "11       DT     PIPE                     162                     241  15.097   \n",
      "12       DT      SVM                     149                     239  20.415   \n",
      "13       DT       RF                     182                     224   4.140   \n",
      "14       DT       MV                     154                     204   6.707   \n",
      "15      ADA      KNN                     242                     154  19.114   \n",
      "16      ADA      BAG                     226                     162  10.229   \n",
      "17      ADA     PIPE                     139                     134   0.059   \n",
      "18      ADA      SVM                     102                     108   0.119   \n",
      "19      ADA       RF                     177                     135   5.388   \n",
      "20      ADA       MV                     154                     120   3.974   \n",
      "21      KNN      BAG                     249                     273   1.013   \n",
      "22      KNN     PIPE                     129                     212  19.718   \n",
      "23      KNN      SVM                     148                     242  22.177   \n",
      "24      KNN       RF                     209                     255   4.364   \n",
      "25      KNN       MV                      76                     130  13.636   \n",
      "26      BAG     PIPE                     182                     241   7.953   \n",
      "27      BAG      SVM                     155                     225  12.529   \n",
      "28      BAG       RF                     117                     139   1.723   \n",
      "29      BAG       MV                     201                     231   1.947   \n",
      "30     PIPE      SVM                     139                     150   0.346   \n",
      "31     PIPE       RF                     202                     165   3.531   \n",
      "32     PIPE       MV                     163                     134   2.640   \n",
      "33      SVM       RF                     176                     128   7.266   \n",
      "34      SVM       MV                     166                     126   5.209   \n",
      "35       RF       MV                     174                     182   0.138   \n",
      "\n",
      "    p-valor  \n",
      "0    0.8383  \n",
      "1    0.0001  \n",
      "2    0.9625  \n",
      "3    0.2802  \n",
      "4    0.0001  \n",
      "5    0.0000  \n",
      "6    0.0352  \n",
      "7    0.0090  \n",
      "8    0.0000  \n",
      "9    0.8995  \n",
      "10   0.3828  \n",
      "11   0.0001  \n",
      "12   0.0000  \n",
      "13   0.0419  \n",
      "14   0.0096  \n",
      "15   0.0000  \n",
      "16   0.0014  \n",
      "17   0.8087  \n",
      "18   0.7301  \n",
      "19   0.0203  \n",
      "20   0.0462  \n",
      "21   0.3141  \n",
      "22   0.0000  \n",
      "23   0.0000  \n",
      "24   0.0367  \n",
      "25   0.0002  \n",
      "26   0.0048  \n",
      "27   0.0004  \n",
      "28   0.1894  \n",
      "29   0.1629  \n",
      "30   0.5564  \n",
      "31   0.0602  \n",
      "32   0.1042  \n",
      "33   0.0070  \n",
      "34   0.0225  \n",
      "35   0.7106  \n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy seaborn pandas matplotlib scikit-learn statsmodels\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (  AdaBoostClassifier,\n",
    "                                BaggingClassifier,\n",
    "                                RandomForestClassifier,\n",
    "                                VotingClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from itertools import combinations\n",
    "\n",
    "# 1) Carga de datos\n",
    "try:\n",
    "    diabetes_df = pd.read_csv('../preprocessing_scripts/Data_preprocessed_10000.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"File not found. Please check the file path.\")\n",
    "\n",
    "X = diabetes_df.drop('Diabetes_binary', axis=1).astype('float32')\n",
    "y = diabetes_df['Diabetes_binary'].values\n",
    "\n",
    "# 2) Train/test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 3) Entrena cada modelo y genera predicciones en el conjunto de validación\n",
    "\n",
    "# 3.1 GaussianNB con umbral optimizado\n",
    "clf_nb = GaussianNB().fit(X_train, y_train)\n",
    "probas_nb = clf_nb.predict_proba(X_val)[:, 1]\n",
    "threshold = 0.08234715264318251\n",
    "y_nb = (probas_nb >= threshold).astype(int)\n",
    "\n",
    "# 3.2 Decision Tree\n",
    "clf_dt = DecisionTreeClassifier(\n",
    "    criterion='gini', max_depth=4,\n",
    "    min_samples_split=2, min_samples_leaf=1,\n",
    "    min_impurity_decrease=0.0,\n",
    "    random_state=42\n",
    ").fit(X_train, y_train)\n",
    "y_dt = clf_dt.predict(X_val)\n",
    "\n",
    "# 3.3 AdaBoost\n",
    "clf_ada = AdaBoostClassifier(\n",
    "    n_estimators=100, random_state=42\n",
    ").fit(X_train, y_train)\n",
    "y_ada = clf_ada.predict(X_val)\n",
    "\n",
    "# 3.4 KNN\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=74, weights='distance')\\\n",
    "    .fit(X_train, y_train)\n",
    "y_knn = clf_knn.predict(X_val)\n",
    "\n",
    "# 3.5 Bagging sobre Decision Tree\n",
    "clf_bg = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=75, random_state=42\n",
    ").fit(X_train, y_train)\n",
    "y_bg = clf_bg.predict(X_val)\n",
    "\n",
    "# 3.6 Pipeline: SelectKBest + KNN\n",
    "clf_pipe = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=mutual_info_classif, k=7)),\n",
    "    ('knn', KNeighborsClassifier(\n",
    "        n_neighbors=39, weights='uniform',\n",
    "        metric='minkowski', p=1.75\n",
    "    ))\n",
    "]).fit(X_train, y_train)\n",
    "y_pipe = clf_pipe.predict(X_val)\n",
    "\n",
    "# 3.7 SVM RBF\n",
    "clf_svm = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVC(kernel='rbf', C=100, gamma=0.001,\n",
    "        probability=True, random_state=42)\n",
    ").fit(X_train, y_train)\n",
    "y_svm = clf_svm.predict(X_val)\n",
    "\n",
    "# 3.8 Random Forest\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=75,random_state=42).fit(X_train,y_train)\n",
    "y_rf = clf_rf.predict(X_val)\n",
    "\n",
    "# 3.9 Majority Voting\n",
    "\n",
    "clf_mv  = VotingClassifier(\n",
    "        estimators=[\n",
    "            (\"nb\", GaussianNB()),\n",
    "            (\"knn\", KNeighborsClassifier(\n",
    "                n_neighbors = 74,\n",
    "                weights = \"distance\"\n",
    "            )),\n",
    "            (\"dt\", DecisionTreeClassifier(random_state=42,\n",
    "                                          criterion=\"gini\", \n",
    "                                          max_depth=4, \n",
    "                                          min_samples_leaf=1, \n",
    "                                          min_impurity_decrease=0.0, \n",
    "                                          min_samples_split=2))\n",
    "        ],\n",
    "        voting = \"hard\"\n",
    "    ).fit(X_train,y_train)\n",
    "y_mv = clf_mv.predict(X_val)\n",
    "\n",
    "# 4) Junta todas las predicciones en un DataFrame\n",
    "preds = pd.DataFrame({\n",
    "    'y_true': y_val,\n",
    "    'NB':     y_nb,\n",
    "    'DT':     y_dt,\n",
    "    'ADA':    y_ada,\n",
    "    'KNN':    y_knn,\n",
    "    'BAG':    y_bg,\n",
    "    'PIPE':   y_pipe,\n",
    "    'SVM':    y_svm,\n",
    "    'RF' :    y_rf,\n",
    "    'MV' :    y_mv\n",
    "})\n",
    "\n",
    "# 5) Función auxiliar para contar b y c\n",
    "def contar_b_c(y_true, y_a, y_b):\n",
    "    ac_a = (y_a == y_true)\n",
    "    ac_b = (y_b == y_true)\n",
    "    b = int(((ac_a) & (~ac_b)).sum())  # A acierta, B falla\n",
    "    c = int(((~ac_a) & (ac_b)).sum())  # A falla, B acierta\n",
    "    return b, c\n",
    "\n",
    "# 6) Prueba de McNemar para cada par de modelos\n",
    "resultados = []\n",
    "for A, B in combinations(['NB','DT','ADA','KNN','BAG','PIPE','SVM','RF','MV'], 2):\n",
    "    b, c = contar_b_c(preds['y_true'], preds[A], preds[B])\n",
    "    tabla = [[0, b],\n",
    "             [c, 0]]\n",
    "    test = mcnemar(tabla, exact=False, correction=True)\n",
    "    resultados.append({\n",
    "        'Modelo A': A,\n",
    "        'Modelo B': B,\n",
    "        'b (A acierta, B falla)': b,\n",
    "        'c (A falla, B acierta)': c,\n",
    "        'χ²': round(test.statistic, 3),\n",
    "        'p-valor': round(test.pvalue, 4)\n",
    "    })\n",
    "\n",
    "df_mcnemar = pd.DataFrame(resultados)\n",
    "\n",
    "# 7) Muestra la tabla de resultados\n",
    "print(df_mcnemar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
