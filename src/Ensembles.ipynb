{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T19:41:17.354688Z",
     "start_time": "2023-12-10T19:41:14.048003Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as ds\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestClassifier,\n",
    "    VotingClassifier,    \n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T19:41:20.865532Z",
     "start_time": "2023-12-10T19:41:20.847571Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HighBP  HighChol  CholCheck       BMI  Smoker  Stroke  \\\n",
      "0        0.0       1.0        1.0 -1.071593     1.0     0.0   \n",
      "1        0.0       0.0        1.0  0.628607     1.0     0.0   \n",
      "2        1.0       1.0        1.0 -0.319133     1.0     0.0   \n",
      "3        0.0       1.0        1.0  0.017644     1.0     0.0   \n",
      "4        1.0       0.0        1.0  2.311887     0.0     0.0   \n",
      "...      ...       ...        ...       ...     ...     ...   \n",
      "9934     0.0       0.0        1.0 -0.319133     1.0     0.0   \n",
      "9935     1.0       1.0        1.0  1.041359     1.0     0.0   \n",
      "9936     1.0       1.0        1.0  0.177702     0.0     0.0   \n",
      "9937     0.0       0.0        1.0 -1.723404     0.0     0.0   \n",
      "9938     1.0       1.0        1.0 -1.279341     0.0     0.0   \n",
      "\n",
      "      HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  ...  AnyHealthcare  \\\n",
      "0                      0.0           1.0     0.0      1.0  ...            1.0   \n",
      "1                      0.0           0.0     1.0      1.0  ...            1.0   \n",
      "2                      0.0           1.0     1.0      1.0  ...            1.0   \n",
      "3                      0.0           0.0     1.0      0.0  ...            1.0   \n",
      "4                      0.0           1.0     1.0      1.0  ...            1.0   \n",
      "...                    ...           ...     ...      ...  ...            ...   \n",
      "9934                   0.0           0.0     0.0      1.0  ...            0.0   \n",
      "9935                   1.0           1.0     0.0      1.0  ...            1.0   \n",
      "9936                   0.0           0.0     1.0      1.0  ...            1.0   \n",
      "9937                   0.0           1.0     1.0      1.0  ...            1.0   \n",
      "9938                   0.0           0.0     1.0      1.0  ...            1.0   \n",
      "\n",
      "      NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
      "0             0.0      4.0       0.0       0.0       0.0  0.0  10.0   \n",
      "1             0.0      3.0       0.0       3.0       1.0  0.0  13.0   \n",
      "2             0.0      2.0       0.0       5.0       0.0  1.0   8.0   \n",
      "3             0.0      3.0       0.0       5.0       0.0  1.0   7.0   \n",
      "4             0.0      4.0      30.0      10.0       1.0  1.0   6.0   \n",
      "...           ...      ...       ...       ...       ...  ...   ...   \n",
      "9934          1.0      2.0       0.0       0.0       0.0  1.0   9.0   \n",
      "9935          1.0      5.0      25.0      30.0       1.0  1.0   8.0   \n",
      "9936          0.0      2.0       0.0       1.0       0.0  0.0   9.0   \n",
      "9937          0.0      1.0       0.0       0.0       0.0  0.0  10.0   \n",
      "9938          0.0      4.0       0.0       3.0       0.0  0.0  12.0   \n",
      "\n",
      "      Education  Income  \n",
      "0           4.0     5.0  \n",
      "1           5.0     4.0  \n",
      "2           6.0     6.0  \n",
      "3           5.0     8.0  \n",
      "4           6.0     3.0  \n",
      "...         ...     ...  \n",
      "9934        5.0     7.0  \n",
      "9935        5.0     8.0  \n",
      "9936        6.0     8.0  \n",
      "9937        5.0     7.0  \n",
      "9938        3.0     1.0  \n",
      "\n",
      "[9939 rows x 21 columns]\n",
      "0       1.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "3       0.0\n",
      "4       1.0\n",
      "       ... \n",
      "9934    0.0\n",
      "9935    0.0\n",
      "9936    1.0\n",
      "9937    0.0\n",
      "9938    0.0\n",
      "Name: Diabetes_binary, Length: 9939, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "diabetes_df = pd.read_csv('../preprocessing_scripts/Data_preprocessed_10000.csv')\n",
    "X, y = diabetes_df.drop(columns=\"Diabetes_binary\"), diabetes_df[\"Diabetes_binary\"]\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:09:58.050090Z",
     "start_time": "2023-12-10T20:09:58.047524Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define a function to measure execution's time. It will be use as a 'decorator'\n",
    "# The idea behind this is just to use it to estimate the time it will take for the\n",
    "# full code to run if you want to know before training with the complete dataset\n",
    "# using a subset of size known in relationship with the full dataset.\n",
    "def compute_executions_time(function):\n",
    "    def wrapper():\n",
    "        start_time = time.time()  # init measuring time\n",
    "        function()  # execute function\n",
    "        print(f\"\\n{time.time() - start_time} seconds\")  # print execution time\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T19:48:57.712663Z",
     "start_time": "2023-12-10T19:48:50.739941Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.64272 [nº estimators (trees): 1]\n",
      "F1-score: 0.55973 [nº estimators (trees): 2]\n",
      "F1-score: 0.68273 [nº estimators (trees): 3]\n",
      "F1-score: 0.63934 [nº estimators (trees): 4]\n",
      "F1-score: 0.70763 [nº estimators (trees): 5]\n",
      "F1-score: 0.67478 [nº estimators (trees): 6]\n",
      "F1-score: 0.71235 [nº estimators (trees): 7]\n",
      "F1-score: 0.69259 [nº estimators (trees): 8]\n",
      "F1-score: 0.72024 [nº estimators (trees): 9]\n",
      "F1-score: 0.70243 [nº estimators (trees): 10]\n",
      "F1-score: 0.72781 [nº estimators (trees): 11]\n",
      "F1-score: 0.70859 [nº estimators (trees): 12]\n",
      "F1-score: 0.73372 [nº estimators (trees): 13]\n",
      "F1-score: 0.71903 [nº estimators (trees): 14]\n",
      "F1-score: 0.72286 [nº estimators (trees): 15]\n",
      "F1-score: 0.71744 [nº estimators (trees): 16]\n",
      "F1-score: 0.72206 [nº estimators (trees): 17]\n",
      "F1-score: 0.72834 [nº estimators (trees): 18]\n",
      "F1-score: 0.73666 [nº estimators (trees): 19]\n",
      "F1-score: 0.72409 [nº estimators (trees): 20]\n",
      "F1-score: 0.73443 [nº estimators (trees): 21]\n",
      "F1-score: 0.72741 [nº estimators (trees): 22]\n",
      "F1-score: 0.73681 [nº estimators (trees): 23]\n",
      "F1-score: 0.73465 [nº estimators (trees): 24]\n",
      "F1-score: 0.73687 [nº estimators (trees): 25]\n",
      "F1-score: 0.72977 [nº estimators (trees): 26]\n",
      "F1-score: 0.73742 [nº estimators (trees): 27]\n",
      "F1-score: 0.73220 [nº estimators (trees): 28]\n",
      "F1-score: 0.73732 [nº estimators (trees): 29]\n",
      "F1-score: 0.73973 [nº estimators (trees): 30]\n",
      "F1-score: 0.73773 [nº estimators (trees): 31]\n",
      "F1-score: 0.73345 [nº estimators (trees): 32]\n",
      "F1-score: 0.74608 [nº estimators (trees): 33]\n",
      "F1-score: 0.73529 [nº estimators (trees): 34]\n",
      "F1-score: 0.74331 [nº estimators (trees): 35]\n",
      "F1-score: 0.73439 [nº estimators (trees): 36]\n",
      "F1-score: 0.73776 [nº estimators (trees): 37]\n",
      "F1-score: 0.73631 [nº estimators (trees): 38]\n",
      "F1-score: 0.74275 [nº estimators (trees): 39]\n",
      "F1-score: 0.74114 [nº estimators (trees): 40]\n",
      "F1-score: 0.73844 [nº estimators (trees): 41]\n",
      "F1-score: 0.73851 [nº estimators (trees): 42]\n",
      "inefficiency breakpoint reached\n",
      "\n",
      "15.790249824523926 seconds\n"
     ]
    }
   ],
   "source": [
    "#determinación de posibles valores de n_estimators\n",
    "\n",
    "@compute_executions_time\n",
    "def random_forest_with_different_n_estimators():\n",
    "    prev_score = float('-inf')\n",
    "\n",
    "    for n_trees in range(1,200,1):\n",
    "        random_forest_classifier = RandomForestClassifier(\n",
    "            n_estimators = n_trees\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            estimator = random_forest_classifier,\n",
    "            X = X,\n",
    "            y = y,\n",
    "            cv=10,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        print(f\"F1-score: {scores.mean():.5f} [nº estimators (trees): {n_trees}]\")\n",
    "\n",
    "        if(abs(scores.mean() - prev_score)  < 0.0001): \n",
    "            print(\"inefficiency breakpoint reached\")\n",
    "            break\n",
    "    \n",
    "        prev_score = scores.mean()\n",
    "        \n",
    "random_forest_with_different_n_estimators();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 'log2', 'n_estimators': 171}\n",
      "0.749383223289077\n"
     ]
    }
   ],
   "source": [
    "#determinacion de mejor combinación de n_estimators y max_features con GridSearch\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\" : range(1,201,10),\n",
    "    \"max_features\": [\"sqrt\", \"log2\", 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "            param_grid=params,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1,\n",
    "            cv=10\n",
    "            )\n",
    "clf.fit(X,y)\n",
    "\n",
    "print(clf.best_params_)\n",
    "best_n_trees_rf = clf.best_params_[\"n_estimators\"]\n",
    "best_max_features_rf = clf.best_params_[\"max_features\"]\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.74843 [criterion: gini]\n",
      "F1-score: 0.74710 [criterion: entropy]\n",
      "F1-score: 0.74766 [criterion: log_loss]\n"
     ]
    }
   ],
   "source": [
    "#determinación de mejor criterion\n",
    "\n",
    "for criteria in [\"gini\", \"entropy\", \"log_loss\"]:\n",
    "        random_forest_classifier = RandomForestClassifier(\n",
    "            n_estimators = best_n_trees_rf,\n",
    "            max_features = best_max_features_rf,\n",
    "            criterion = criteria\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            estimator = random_forest_classifier,\n",
    "            X = X,\n",
    "            y = y,\n",
    "            cv=10,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        print(f\"F1-score: {scores.mean():.5f} [criterion: {criteria}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.74947 [max_depth: None]\n",
      "F1-score: 0.74980 [max_depth: 5]\n",
      "F1-score: 0.75557 [max_depth: 10]\n",
      "F1-score: 0.75319 [max_depth: 11]\n",
      "F1-score: 0.75288 [max_depth: 12]\n",
      "F1-score: 0.75370 [max_depth: 13]\n",
      "F1-score: 0.75185 [max_depth: 14]\n",
      "F1-score: 0.75206 [max_depth: 15]\n",
      "F1-score: 0.75260 [max_depth: 16]\n",
      "F1-score: 0.74818 [max_depth: 17]\n",
      "F1-score: 0.74660 [max_depth: 18]\n",
      "F1-score: 0.74875 [max_depth: 19]\n",
      "F1-score: 0.74991 [max_depth: 20]\n",
      "F1-score: 0.74842 [max_depth: 25]\n",
      "F1-score: 0.74611 [max_depth: 30]\n",
      "F1-score: 0.74444 [max_depth: 35]\n",
      "F1-score: 0.74937 [max_depth: 40]\n",
      "F1-score: 0.74704 [max_depth: 45]\n",
      "F1-score: 0.74753 [max_depth: 50]\n"
     ]
    }
   ],
   "source": [
    "#determinación de mejor max_depth\n",
    "\n",
    "for depth in [None, 5,10,11,12,13,14,15,16,17,18,19,20,25,30,35,40,45,50]:\n",
    "        random_forest_classifier = RandomForestClassifier(\n",
    "            n_estimators = best_n_trees_rf,\n",
    "            max_features = best_max_features_rf,\n",
    "            max_depth = depth\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            estimator = random_forest_classifier,\n",
    "            X = X,\n",
    "            y = y,\n",
    "            cv=10,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        print(f\"F1-score: {scores.mean():.5f} [max_depth: {depth}]\")\n",
    "\n",
    "best_depth_rf = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.75475 [min_samples_split: 2]\n",
      "F1-score: 0.75519 [min_samples_split: 3]\n",
      "F1-score: 0.75472 [min_samples_split: 4]\n",
      "F1-score: 0.75303 [min_samples_split: 5]\n",
      "F1-score: 0.75422 [min_samples_split: 6]\n",
      "F1-score: 0.75610 [min_samples_split: 7]\n",
      "F1-score: 0.75589 [min_samples_split: 8]\n",
      "F1-score: 0.75617 [min_samples_split: 9]\n",
      "F1-score: 0.75507 [min_samples_split: 10]\n",
      "F1-score: 0.75768 [min_samples_split: 11]\n",
      "F1-score: 0.75441 [min_samples_split: 12]\n",
      "F1-score: 0.75410 [min_samples_split: 13]\n",
      "F1-score: 0.75420 [min_samples_split: 14]\n",
      "F1-score: 0.75405 [min_samples_split: 15]\n",
      "F1-score: 0.75529 [min_samples_split: 16]\n",
      "F1-score: 0.75186 [min_samples_split: 17]\n",
      "F1-score: 0.75334 [min_samples_split: 18]\n",
      "F1-score: 0.75406 [min_samples_split: 19]\n"
     ]
    }
   ],
   "source": [
    "#determinación de mejor min_samples_split\n",
    "\n",
    "for min in range(2,20):\n",
    "        random_forest_classifier = RandomForestClassifier(\n",
    "            n_estimators = best_n_trees_rf,\n",
    "            max_features = best_max_features_rf,\n",
    "            max_depth = best_depth_rf,\n",
    "            min_samples_split = min\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            estimator = random_forest_classifier,\n",
    "            X = X,\n",
    "            y = y,\n",
    "            cv=10,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        print(f\"F1-score: {scores.mean():.5f} [min_samples_split: {min}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.75405 [min_samples_leaf: 1]\n",
      "F1-score: 0.75480 [min_samples_leaf: 2]\n",
      "F1-score: 0.75416 [min_samples_leaf: 3]\n",
      "F1-score: 0.75438 [min_samples_leaf: 4]\n",
      "F1-score: 0.75509 [min_samples_leaf: 5]\n",
      "F1-score: 0.75465 [min_samples_leaf: 6]\n",
      "F1-score: 0.75375 [min_samples_leaf: 7]\n",
      "F1-score: 0.75489 [min_samples_leaf: 8]\n",
      "F1-score: 0.75319 [min_samples_leaf: 9]\n",
      "F1-score: 0.75393 [min_samples_leaf: 10]\n",
      "F1-score: 0.75420 [min_samples_leaf: 11]\n",
      "F1-score: 0.75465 [min_samples_leaf: 12]\n",
      "F1-score: 0.75422 [min_samples_leaf: 13]\n",
      "F1-score: 0.75345 [min_samples_leaf: 14]\n",
      "F1-score: 0.75457 [min_samples_leaf: 15]\n",
      "F1-score: 0.75485 [min_samples_leaf: 16]\n",
      "F1-score: 0.75200 [min_samples_leaf: 17]\n",
      "F1-score: 0.75486 [min_samples_leaf: 18]\n",
      "F1-score: 0.75381 [min_samples_leaf: 19]\n"
     ]
    }
   ],
   "source": [
    "#determinación de mejor min_samples_leaf\n",
    "\n",
    "for min in range(1,20):\n",
    "        random_forest_classifier = RandomForestClassifier(\n",
    "            n_estimators = best_n_trees_rf,\n",
    "            max_features = best_max_features_rf,\n",
    "            max_depth = best_depth_rf,\n",
    "            min_samples_leaf = min\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            estimator = random_forest_classifier,\n",
    "            X = X,\n",
    "            y = y,\n",
    "            cv=10,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        print(f\"F1-score: {scores.mean():.5f} [min_samples_leaf: {min}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **Bagging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.696 [estimator: DecisionTreeClassifier()]\n",
      "F1-score: 0.706 [estimator: KNeighborsClassifier()]\n"
     ]
    }
   ],
   "source": [
    "# determinación de base estimator\n",
    "\n",
    "for est in [DecisionTreeClassifier(), KNeighborsClassifier()]:\n",
    "    scores = cross_val_score(\n",
    "        BaggingClassifier(\n",
    "            estimator = est,\n",
    "        ), \n",
    "        X, \n",
    "        y, \n",
    "        cv = 10, \n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f\"F1-score: {scores.mean():.5f} [estimator: {est}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:09:43.713241Z",
     "start_time": "2023-12-10T20:09:11.620109Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.64672 [nº estimators: 1]\n",
      "F1-score: 0.67973 [nº estimators: 3]\n",
      "F1-score: 0.69335 [nº estimators: 5]\n",
      "F1-score: 0.70235 [nº estimators: 7]\n",
      "F1-score: 0.70763 [nº estimators: 9]\n",
      "F1-score: 0.71839 [nº estimators: 11]\n",
      "F1-score: 0.71516 [nº estimators: 13]\n",
      "F1-score: 0.72060 [nº estimators: 15]\n",
      "F1-score: 0.72549 [nº estimators: 17]\n",
      "F1-score: 0.72298 [nº estimators: 19]\n",
      "F1-score: 0.72436 [nº estimators: 21]\n",
      "F1-score: 0.72667 [nº estimators: 23]\n",
      "F1-score: 0.72505 [nº estimators: 25]\n",
      "F1-score: 0.72929 [nº estimators: 27]\n",
      "F1-score: 0.72809 [nº estimators: 29]\n",
      "F1-score: 0.72950 [nº estimators: 31]\n",
      "F1-score: 0.72696 [nº estimators: 33]\n",
      "F1-score: 0.73052 [nº estimators: 35]\n",
      "F1-score: 0.73063 [nº estimators: 37]\n",
      "F1-score: 0.73051 [nº estimators: 39]\n",
      "F1-score: 0.73078 [nº estimators: 41]\n",
      "F1-score: 0.73295 [nº estimators: 43]\n",
      "F1-score: 0.72661 [nº estimators: 45]\n",
      "F1-score: 0.73147 [nº estimators: 47]\n",
      "F1-score: 0.73007 [nº estimators: 49]\n"
     ]
    }
   ],
   "source": [
    "# determinación de valores de n_estimators\n",
    "prev_score = float('-inf')\n",
    "\n",
    "for nest in range(1,51,2):\n",
    "    scores = cross_val_score(\n",
    "        BaggingClassifier(\n",
    "            estimator = DecisionTreeClassifier(),\n",
    "            n_estimators = nest\n",
    "        ), \n",
    "        X, \n",
    "        y, \n",
    "        cv = 10, \n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f\"F1-score: {scores.mean():.5f} [nº estimators: {nest}]\")\n",
    "\n",
    "    if(abs(scores.mean() - prev_score)  < 0.0001): \n",
    "            print(\"inefficiency breakpoint reached\")\n",
    "            break\n",
    "    \n",
    "    prev_score = scores.mean()\n",
    "\n",
    "best_n_est_bg = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.71842 [max_samples: 11]\n",
      "F1-score: 0.72010 [max_samples: 13]\n",
      "F1-score: 0.71038 [max_samples: 15]\n",
      "F1-score: 0.71312 [max_samples: 17]\n",
      "F1-score: 0.72107 [max_samples: 19]\n",
      "F1-score: 0.71852 [max_samples: 21]\n",
      "F1-score: 0.72406 [max_samples: 23]\n",
      "F1-score: 0.72343 [max_samples: 25]\n",
      "F1-score: 0.71840 [max_samples: 27]\n",
      "F1-score: 0.72067 [max_samples: 29]\n",
      "F1-score: 0.72416 [max_samples: 31]\n",
      "F1-score: 0.72636 [max_samples: 33]\n",
      "F1-score: 0.72836 [max_samples: 35]\n",
      "F1-score: 0.72255 [max_samples: 37]\n",
      "F1-score: 0.73415 [max_samples: 39]\n",
      "F1-score: 0.72304 [max_samples: 41]\n",
      "F1-score: 0.72495 [max_samples: 43]\n",
      "F1-score: 0.73279 [max_samples: 45]\n",
      "F1-score: 0.72451 [max_samples: 47]\n",
      "F1-score: 0.72535 [max_samples: 49]\n",
      "F1-score: 0.72839 [max_samples: 51]\n",
      "F1-score: 0.72973 [max_samples: 53]\n",
      "F1-score: 0.73428 [max_samples: 55]\n",
      "F1-score: 0.72462 [max_samples: 57]\n",
      "F1-score: 0.72166 [max_samples: 59]\n",
      "F1-score: 0.73788 [max_samples: 61]\n",
      "F1-score: 0.73325 [max_samples: 63]\n",
      "F1-score: 0.72980 [max_samples: 65]\n",
      "F1-score: 0.73743 [max_samples: 67]\n",
      "F1-score: 0.73134 [max_samples: 69]\n",
      "F1-score: 0.73285 [max_samples: 71]\n",
      "F1-score: 0.73214 [max_samples: 73]\n",
      "F1-score: 0.73058 [max_samples: 75]\n",
      "F1-score: 0.73389 [max_samples: 77]\n",
      "F1-score: 0.73774 [max_samples: 79]\n",
      "F1-score: 0.73577 [max_samples: 81]\n",
      "F1-score: 0.73117 [max_samples: 83]\n",
      "F1-score: 0.73584 [max_samples: 85]\n",
      "F1-score: 0.73459 [max_samples: 87]\n",
      "F1-score: 0.73963 [max_samples: 89]\n",
      "F1-score: 0.73226 [max_samples: 91]\n",
      "F1-score: 0.73018 [max_samples: 93]\n",
      "F1-score: 0.73049 [max_samples: 95]\n",
      "F1-score: 0.73473 [max_samples: 97]\n",
      "F1-score: 0.73039 [max_samples: 99]\n"
     ]
    }
   ],
   "source": [
    "# determinación de valores de max_samples\n",
    "for max in range(11,101,2):\n",
    "    scores = cross_val_score(\n",
    "        BaggingClassifier(\n",
    "            estimator = DecisionTreeClassifier(),\n",
    "            n_estimators = best_n_est_bg,\n",
    "            max_samples = max\n",
    "        ), \n",
    "        X, \n",
    "        y, \n",
    "        cv = 10, \n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f\"F1-score: {scores.mean():.5f} [max_samples: {max}]\")\n",
    "\n",
    "best_max_samples_bg = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.265 [max_samples: 1]\n",
      "F1-score: 0.453 [max_samples: 2]\n",
      "F1-score: 0.541 [max_samples: 3]\n",
      "F1-score: 0.592 [max_samples: 4]\n",
      "F1-score: 0.681 [max_samples: 5]\n",
      "F1-score: 0.678 [max_samples: 6]\n",
      "F1-score: 0.710 [max_samples: 7]\n",
      "F1-score: 0.686 [max_samples: 8]\n",
      "F1-score: 0.682 [max_samples: 9]\n",
      "F1-score: 0.691 [max_samples: 10]\n",
      "F1-score: 0.703 [max_samples: 11]\n",
      "F1-score: 0.695 [max_samples: 12]\n",
      "F1-score: 0.705 [max_samples: 13]\n",
      "F1-score: 0.705 [max_samples: 14]\n",
      "F1-score: 0.708 [max_samples: 15]\n",
      "F1-score: 0.715 [max_samples: 16]\n",
      "F1-score: 0.710 [max_samples: 17]\n",
      "F1-score: 0.718 [max_samples: 18]\n",
      "F1-score: 0.715 [max_samples: 19]\n",
      "F1-score: 0.719 [max_samples: 20]\n",
      "F1-score: 0.713 [max_samples: 21]\n"
     ]
    }
   ],
   "source": [
    "# determinación de valores de max_features\n",
    "for max in range(1,22,1):\n",
    "    scores = cross_val_score(\n",
    "        BaggingClassifier(\n",
    "            estimator = KNeighborsClassifier(n_neighbors=30),\n",
    "            n_estimators = best_n_est_bg,\n",
    "            max_samples = max\n",
    "        ), \n",
    "        X, \n",
    "        y, \n",
    "        cv = 10, \n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f\"F1-score: {scores.mean():.5f} [max_samples: {max}]\")\n",
    "\n",
    "best_max_features_bg = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **Extra Trees Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:01:23.081508Z",
     "start_time": "2023-12-10T20:01:17.806463Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@compute_executions_time\n",
    "def execute_extra_trees_classifier_with_different_estimators_and_cv(cv=10):\n",
    "    for n_trees in [1, 2, 5, 10, 20, 50, 100, 200]:\n",
    "        extra_trees_classifier = ExtraTreesClassifier(\n",
    "            n_estimators = n_trees\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            estimator = extra_trees_classifier,\n",
    "            X = X,\n",
    "            y = y,\n",
    "            cv = cv,\n",
    "            scoring = \"f1\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        print(f\"F1-score: {scores.mean():.3f} [nº estimators (trees): {n_trees}]\")\n",
    "\n",
    "execute_extra_trees_classifier_with_different_estimators_and_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **Voting Scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:05:55.898477Z",
     "start_time": "2023-12-10T20:05:53.439291Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params fo Knn: {'n_neighbors': 30, 'weights': 'uniform'} - Accuracy: 0.7249186964688432\n",
      "F1-score: 0.713 [Naive Bayes]\n",
      "F1-score: 0.733 [Knn (3)]\n",
      "F1-score: 0.647 [Dec. Tree]\n",
      "F1-score: 0.735 [Majority Voting with hard voting]\n",
      "F1-score: 0.730 [Majority Voting with soft voting]\n",
      "\n",
      "11.430985927581787 seconds\n"
     ]
    }
   ],
   "source": [
    "@compute_executions_time\n",
    "def execute_voting_scheme_different_estimators_grid_search_and_cv(cv = 10):\n",
    "    naive_bayes = GaussianNB()\n",
    "    k_neighbors = KNeighborsClassifier()\n",
    "    params_space = {\n",
    "        \"n_neighbors\": list(range(1, 51, 1)),\n",
    "        \"weights\": [\"distance\", \"uniform\"]\n",
    "    }\n",
    "\n",
    "    #search for best metaparameters for knn\n",
    "    clf = GridSearchCV(\n",
    "        k_neighbors, \n",
    "        param_grid = params_space,\n",
    "        cv = cv,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "    clf.fit(X, y)\n",
    "    best_parameters_for_knn = clf.best_params_\n",
    "    print(f\"Best Params fo Knn: {clf.best_params_} - Accuracy: {clf.best_score_}\")\n",
    "\n",
    "    clf2 = KNeighborsClassifier(\n",
    "        n_neighbors = best_parameters_for_knn[\"n_neighbors\"],\n",
    "        weights = best_parameters_for_knn[\"weights\"]\n",
    "    )\n",
    "\n",
    "    clf3 = DecisionTreeClassifier()\n",
    "\n",
    "    for clf, label in zip([naive_bayes, clf2, clf3], [\"Naive Bayes\",\"Knn (3)\", \"Dec. Tree\", ]):\n",
    "        scores = cross_val_score(\n",
    "            clf, \n",
    "            X, \n",
    "            y, \n",
    "            cv = cv, \n",
    "            n_jobs=-1,\n",
    "            scoring = \"f1\"\n",
    "        )\n",
    "        print(f\"F1-score: {scores.mean():.3f} [{label}]\")\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Just to avoid warnings\n",
    "\n",
    "    for vot in [\"hard\", \"soft\"]:\n",
    "        voting_classifier = VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"nb\", naive_bayes),\n",
    "                (\"knn3\", clf2),\n",
    "                (\"dt\", clf3)\n",
    "            ],\n",
    "            voting = vot\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            voting_classifier,\n",
    "            X,\n",
    "            y,\n",
    "            cv = cv,\n",
    "            n_jobs=-1,\n",
    "            scoring = \"f1\")\n",
    "        print(\"F1-score: %0.3f [%s]\" % (scores.mean() , f\"Majority Voting with {vot} voting\"))\n",
    "\n",
    "execute_voting_scheme_different_estimators_grid_search_and_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **Ada Boost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-10T20:08:43.401870Z",
     "start_time": "2023-12-10T20:07:54.368748Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.694 [nº estimators: 1]\n",
      "F1-score: 0.694 [nº estimators: 2]\n",
      "F1-score: 0.736 [nº estimators: 5]\n",
      "F1-score: 0.746 [nº estimators: 10]\n",
      "F1-score: 0.746 [nº estimators: 20]\n",
      "F1-score: 0.750 [nº estimators: 50]\n",
      "F1-score: 0.751 [nº estimators: 100]\n",
      "F1-score: 0.753 [nº estimators: 200]\n",
      "\n",
      "73.57335209846497 seconds\n"
     ]
    }
   ],
   "source": [
    "@compute_executions_time\n",
    "def execute_ada_boost_classifier_for_different_classifiers(cv=50):\n",
    "    for n_estimators in [1, 2, 5, 10, 20, 50, 100, 200]:\n",
    "        ada_boos_classifier = AdaBoostClassifier(\n",
    "            n_estimators=n_estimators\n",
    "        )\n",
    "        scores = cross_val_score(\n",
    "            ada_boos_classifier,\n",
    "            X,\n",
    "            y,\n",
    "            cv = cv,\n",
    "            jobs=-1,\n",
    "            scoring = \"f1\"\n",
    "        )\n",
    "        print(f\"F1-score: {scores.mean():.3f} [nº estimators: {n_estimators}]\")\n",
    "\n",
    "execute_ada_boost_classifier_for_different_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 1.6, 'n_estimators': 81}\n",
      "0.755560393312526\n"
     ]
    }
   ],
   "source": [
    "#determinacion de mejor combinación de n_estimators y learning_rate con GridSearch\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\" : range(1,201,10),\n",
    "    \"learning_rate\": [0.1,0.5,1.1,1.6,2.1,2.6,3.1,3.6,4.1,4.6,5.1]\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(estimator=AdaBoostClassifier(),\n",
    "            param_grid=params,\n",
    "            scoring=\"f1\",\n",
    "            n_jobs=-1,\n",
    "            cv=10\n",
    "            )\n",
    "clf.fit(X,y)\n",
    "\n",
    "print(clf.best_params_)\n",
    "best_n_est_ada = clf.best_params_[\"n_estimators\"]\n",
    "best_learning_rate_ada = clf.best_params_[\"learning_rate\"]\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.756 [max_samples: DecisionTreeClassifier(max_depth=1)]\n",
      "F1-score: 0.704 [max_samples: GaussianNB()]\n"
     ]
    }
   ],
   "source": [
    "# determinación de valores de max_features\n",
    "for est in [DecisionTreeClassifier(max_depth=1),GaussianNB()]:\n",
    "    scores = cross_val_score(\n",
    "        AdaBoostClassifier(\n",
    "            estimator = est,\n",
    "            n_estimators = best_n_est_ada,\n",
    "            learning_rate=best_learning_rate_ada\n",
    "        ), \n",
    "        X, \n",
    "        y, \n",
    "        cv = 10, \n",
    "        scoring=\"f1\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    print(f\"F1-score: {scores.mean():.3f} [max_samples: {est}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Comparison between classfiers**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
